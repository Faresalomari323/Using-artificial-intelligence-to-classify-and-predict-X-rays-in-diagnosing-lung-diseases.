{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20667048-d7a0-4edf-a3d9-4d72ca3eb9dc",
   "metadata": {},
   "source": [
    "# استراد المكتابات "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ea1ee3-13eb-479a-aa70-b8ae1975dee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Miscellaneous\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "# Turn off tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "# For Data Processing & ML Models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from PIL import Image, ImageEnhance\n",
    "import cv2\n",
    "\n",
    "# For Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "# Enable offline usage of plotly\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode(connected=True)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a4ee282-bd37-45b7-8b66-9e679ff8ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    IMAGE_SIZE = 128\n",
    "\n",
    "    # Data Augmentation\n",
    "    BRIGHTNESS = (0.64, 1.37) # (MIN, MAX)\n",
    "    CONTRAST   = (0.64, 1.37) # (MIN, MAX)\n",
    "\n",
    "    # Train-Val Split\n",
    "    TRAIN_VAL_SPLIT = 0.7 # 80% of all the samples are used for training, and the rest for validation\n",
    "\n",
    "    # Model Training\n",
    "    BATCH_SIZE = 2\n",
    "    EPOCHS = 1\n",
    "    LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d8fa8a-2c73-40e8-9ad9-ee889ecdafde",
   "metadata": {},
   "source": [
    "#   TensorFlow تحميل الصور وتجهيزها للاستخدام في "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d485b86-9fb4-4ee7-a98f-18d2443f4894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# تحديد مسارات مجموعات البيانات\n",
    "train_data_dir = r'C:\\Users\\ibrahim IA\\Desktop\\XRay_1\\train'\n",
    "validation_data_dir = r'C:\\Users\\ibrahim IA\\Desktop\\XRay_1\\val'\n",
    "test_data_dir = r'C:\\Users\\ibrahim IA\\Desktop\\XRay_1\\test'\n",
    "\n",
    "# تحديد الحجم والدفعة لعملية التحميل\n",
    "img_width, img_height = 150, 150\n",
    "batch_size = 32\n",
    "\n",
    "# تحديد مولدات الصور لكل مجموعة\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6c1e3f-c9b5-41af-8f7b-a1e8cef980e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(100)\n",
    "np.random.seed(100)\n",
    "\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0143757-50ef-41d7-8152-e09c642aa82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directories = [\"C:\\\\Users\\\\ibrahim IA\\\\Desktop\\\\XRay_1\\\\test\\\\\",\n",
    "                    \"C:\\\\Users\\\\ibrahim IA\\\\Desktop\\\\XRay_1\\\\train\\\\\",\n",
    "                    \"C:\\\\Users\\\\ibrahim IA\\\\Desktop\\\\XRay_1\\\\val\\\\\"]\n",
    "\n",
    "all_paths = []\n",
    "all_labels = []\n",
    "\n",
    "for data_dir in data_directories:\n",
    "    for label in os.listdir(data_dir):\n",
    "        for image in os.listdir(data_dir+label):\n",
    "            all_paths.append(data_dir+label+'/'+image)\n",
    "            if label=='TURBERCULOSIS':\n",
    "                all_labels.append('TUBERCULOSIS')\n",
    "            else:\n",
    "                all_labels.append(label)\n",
    "\n",
    "all_paths, all_labels = shuffle(all_paths, all_labels)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df = pd.DataFrame({'path':all_paths, 'label':all_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76625988-fba5-48cc-8280-5e3cd236053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "# هنا يتم خلط all_paths و all_labels\n",
    "all_paths, all_labels = shuffle(all_paths, all_labels)\n",
    "\n",
    "data_directories = [\"C:\\\\Users\\\\ibrahim IA\\\\Desktop\\\\XRay_1\\\\test\\\\\",\n",
    "                    \"C:\\\\Users\\\\ibrahim IA\\\\Desktop\\\\XRay_1\\\\train\\\\\",\n",
    "                    \"C:\\\\Users\\\\ibrahim IA\\\\Desktop\\\\XRay_1\\\\val\\\\\"]\n",
    "\n",
    "all_paths = []\n",
    "all_labels = []\n",
    "\n",
    "for data_dir in data_directories:\n",
    "    for label in os.listdir(data_dir):\n",
    "        for image in os.listdir(data_dir+label):\n",
    "            all_paths.append(data_dir+label+'/'+image)\n",
    "            if label=='TURBERCULOSIS':\n",
    "                all_labels.append('TURBERCULOSIS')\n",
    "            else:\n",
    "                all_labels.append(label)\n",
    "\n",
    "all_paths, all_labels = shuffle(all_paths, all_labels)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df = pd.DataFrame({'path':all_paths, 'label':all_labels})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d0ca19-341b-4c11-b740-f6a59a193a53",
   "metadata": {},
   "source": [
    "# رسم بيانات"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a2eb40-e080-4c82-acfb-83ce961c1930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# بيانات التدريب والاختبار\n",
    "train_data = [6376, 1245, 1694]  \n",
    "labels = ['Training', 'Validation', 'Testing']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(labels, train_data, color=['blue', 'orange', 'green'])\n",
    "plt.xlabel('Data Types')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Distribution of Images in Different Sets')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2813fb65-1336-4bb6-8d38-9a01aee18d5f",
   "metadata": {},
   "source": [
    "# عرض بعض الإحصائيات حول بيانات الصور وعرض أمثلة منها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8020580c-84b9-4506-9446-ce00e8da54c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 13})\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "# plotting data on chart\n",
    "plt.pie(list(df.label.value_counts()),\n",
    "        labels=list(df.label.value_counts().index),\n",
    "        colors=['#43b0c1', '#368d9a', '#286a74', '#69c0cd'],\n",
    "        autopct='%.0f%%', wedgeprops = { 'linewidth' : 7, 'edgecolor' : 'white' })\n",
    "\n",
    "my_circle=plt.Circle((0,0), 0.675, color='white')\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.title('Dataset\\nDistribution', x=0.5, y=0.45) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8092c1-be21-4f4c-aad1-830ab698cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image):\n",
    "    # Convert input image from numpy to PIL Image\n",
    "    image = Image.fromarray(np.uint8(image)) \n",
    "    # Select brightness and contrast factors\n",
    "    brightness_factor = random.uniform(cfg.BRIGHTNESS[0],cfg.BRIGHTNESS[1])\n",
    "    contrast_factor = random.uniform(cfg.CONTRAST[0],cfg.CONTRAST[1])\n",
    "    # Apply Transformations\n",
    "    image = ImageEnhance.Brightness(image).enhance(brightness_factor)\n",
    "    image = ImageEnhance.Contrast(image).enhance(contrast_factor)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f4a24e-aa8a-4526-80a3-cc8dcb115821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_images(paths, augment=True):\n",
    "    '''\n",
    "    Given a list of paths to images, this function returns the images as arrays, and conditionally augments them\n",
    "    '''\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        image = load_img(path, target_size=(cfg.IMAGE_SIZE,cfg.IMAGE_SIZE))\n",
    "        if augment:\n",
    "            image = augment_image(image)\n",
    "        image = np.array(image)\n",
    "        image = image/image.max()\n",
    "        images.append(image)\n",
    "    return np.array(images)\n",
    "\n",
    "# Randomly select and plot a few images with augmentation\n",
    "k = random.randint(0,5000)\n",
    "image_paths = list(df.path[k:k+10])\n",
    "labels = list(df.label[k:k+10])\n",
    "images = open_images(image_paths, augment=True)\n",
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "\n",
    "for i in range(0, 10):\n",
    "    fig.add_subplot(2, 5, i+1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.axis('off')\n",
    "    plt.title(labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7610c6af-7c6d-402c-b56b-0fd25ed209e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['NORMAL', 'TURBERCULOSIS', 'PNEUMONIA', 'COVID19']\n",
    "label_encoder = {'NORMAL': 0, 'TURBERCULOSIS': 1, 'PNEUMONIA': 2, 'COVID19': 3}\n",
    "label_decoder = {0: 'NORMAL', 1: 'TURBERCULOSIS', 2: 'PNEUMONIA', 3: 'COVID19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca9fc42-8fed-4d5e-ae26-5a242fd162a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# عرض بعض الصور من مجموعة البيانات\n",
    "def plot_images(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# عرض بعض الصور من مجموعة التدريب\n",
    "sample_training_images, _ = next(train_generator)\n",
    "plot_images(sample_training_images[:10]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a656f400-4e9f-4b29-b0e0-8fedd323af15",
   "metadata": {},
   "source": [
    "# نموذج CNN & VGG16 باستخدام TensorFlow/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6415ec-59ba-468f-877a-5ab54997c9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3, VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# تعيين مسارات البيانات\n",
    "train_data_dir = r'C:\\Users\\ibrahim IA\\Desktop\\XRay1\\train'\n",
    "validation_data_dir = r'C:\\Users\\ibrahim IA\\Desktop\\XRay_1\\val'\n",
    "test_data_dir = r'C:\\Users\\ibrahim IA\\Desktop\\XRay_1\\test'\n",
    "\n",
    "# تحديد الأبعاد\n",
    "img_width, img_height = 224, 224\n",
    "batch_size = 32\n",
    "num_classes = 4\n",
    "\n",
    "# إعداد المولدات\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# تحضير البيانات\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# تحميل نموذج VGG16\n",
    "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# بناء النموذج\n",
    "model = Sequential()\n",
    "model.add(vgg_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# تجميد طبقات VGG16\n",
    "for layer in vgg_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# تحديد الخوارزمية والتدريب\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "# تقييم النموذج\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(f'Test Loss: {test_loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6b4460-519a-445c-88d1-6f652140c4c0",
   "metadata": {},
   "source": [
    "# عملية التدريب"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409d3d19-5e04-4349-a02d-b3e81da57b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[:int(cfg.TRAIN_VAL_SPLIT*len(df))]\n",
    "df_val = df[int(cfg.TRAIN_VAL_SPLIT*len(df)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f0dc4e-88aa-432c-803d-d9a05be5491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 13})\n",
    "fig = plt.figure(figsize=(14, 7))\n",
    "\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.pie(list(df_train.label.value_counts()),\n",
    "        labels=list(df_train.label.value_counts().index),\n",
    "        colors=['#43b0c1', '#368d9a', '#286a74', '#69c0cd'],\n",
    "        autopct='%.0f%%', wedgeprops = { 'linewidth' : 7, 'edgecolor' : 'white' })\n",
    "\n",
    "my_circle=plt.Circle((0,0), 0.675, color='white')\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.axis('off')\n",
    "plt.title('Training', x=0.5, y=0.5) \n",
    "\n",
    "\n",
    "fig.add_subplot(1, 2, 2)\n",
    "plt.pie(list(df_val.label.value_counts()),\n",
    "        labels=list(df_val.label.value_counts().index),\n",
    "        colors=['#43b0c1', '#368d9a', '#286a74', '#69c0cd'],\n",
    "        autopct='%.0f%%', wedgeprops = { 'linewidth' : 7, 'edgecolor' : 'white' })\n",
    "\n",
    "my_circle=plt.Circle((0,0), 0.675, color='white')\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.axis('off')\n",
    "plt.title('Validation', x=0.5, y=0.5) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2db529-c66c-4e1b-a19f-036cd9cce185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(df, batch_size=cfg.BATCH_SIZE, augment=True, epochs=cfg.EPOCHS):\n",
    "    for e in range(epochs):\n",
    "        for x in range(0,len(df), batch_size):\n",
    "            image_paths = df.path[x:x+batch_size]\n",
    "            images = open_images(image_paths, augment=augment)\n",
    "            labels = df.label[x:x+batch_size]\n",
    "            labels = [label_encoder[label] for label in labels]\n",
    "            yield images, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7396a866-b27e-4f78-a805-105690fa9f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating generators for training and validation. You can change the parameters in the configuration section.\n",
    "train_data_generator = data_generator(df_train, batch_size=cfg.BATCH_SIZE, augment=True, epochs=cfg.EPOCHS)\n",
    "train_steps = int(len(df_train)/cfg.BATCH_SIZE)\n",
    "\n",
    "val_data_generator = data_generator(df_val, batch_size=cfg.BATCH_SIZE, augment=False, epochs=cfg.EPOCHS)\n",
    "val_steps = int(len(df_val)/cfg.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c49b51-d9eb-499e-9645-a0ac1193a8e3",
   "metadata": {},
   "source": [
    "# النموذج ( model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5323a8a1-8686-4b47-84a6-3e4b988dcaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential(name='classifier')\n",
    "model.add(layers.Input(shape=(cfg.IMAGE_SIZE, cfg.IMAGE_SIZE, 3), name='input'))\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', padding='same', name='block1_conv1'))\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', padding='same', name='block1_conv2'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2), name='pool1'))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu', padding='same', name='block2_conv1'))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu', padding='same', name='block2_conv2'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2), name='pool2'))\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu', padding='same', name='block3_conv1'))\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu', padding='same', name='block3_conv2'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2), name='pool3'))\n",
    "model.add(layers.Flatten(name='flatten'))\n",
    "model.add(layers.Dropout(0.3, name='dropout1'))\n",
    "model.add(layers.Dense(128, activation='relu', name='dense1'))\n",
    "model.add(layers.Dense(4, activation='softmax', name='final'))\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=cfg.LEARNING_RATE),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb626fd8-b131-47d5-86f4-09e9d188e0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, optimizers\n",
    "\n",
    "# تعيين مسارات البيانات\n",
    "train_data_dir = r'C:\\Users\\ibrahim IA\\Desktop\\XRay1\\train'\n",
    "validation_data_dir = r'C:\\Users\\ibrahim IA\\Desktop\\XRay_1\\val'\n",
    "test_data_dir = r'C:\\Users\\ibrahim IA\\Desktop\\XRay_1\\test'\n",
    "\n",
    "# تحديد الأبعاد\n",
    "img_width, img_height = 150, 150\n",
    "batch_size = 32\n",
    "num_classes = 4\n",
    "\n",
    "\n",
    "# تحسينات على الشبكة العصبية\n",
    "model = models.Sequential(name='classifier')\n",
    "model.add(layers.Input(shape=(cfg.IMAGE_SIZE, cfg.IMAGE_SIZE, 3), name='input'))\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', padding='same', name='block1_conv1'))\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', padding='same', name='block1_conv2'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2), name='pool1'))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu', padding='same', name='block2_conv1'))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu', padding='same', name='block2_conv2'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2), name='pool2'))\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu', padding='same', name='block3_conv1'))\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu', padding='same', name='block3_conv2'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2), name='pool3'))\n",
    "model.add(layers.Flatten(name='flatten'))\n",
    "model.add(layers.Dropout(0.5, name='dropout1'))  # زيادة نسبة الإسقاط\n",
    "model.add(layers.Dense(256, activation='relu', name='dense1'))  # زيادة عدد الوحدات\n",
    "model.add(layers.Dropout(0.3, name='dropout2'))  # إضافة إسقاط إضافي\n",
    "model.add(layers.Dense(4, activation='softmax', name='final'))\n",
    "\n",
    "# Model compilation\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=cfg.LEARNING_RATE),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "class cfg:\n",
    "    IMAGE_SIZE = 128\n",
    "\n",
    "    # Data Augmentation\n",
    "    BRIGHTNESS = (0.64, 1.37) # (MIN, MAX)\n",
    "    CONTRAST   = (0.64, 1.37) # (MIN, MAX)\n",
    "\n",
    "    # Train-Val Split\n",
    "    TRAIN_VAL_SPLIT = 0.7 # 80% of all the samples are used for training, and the rest for validation\n",
    "\n",
    "    # Model Training\n",
    "    BATCH_SIZE = 2\n",
    "    EPOCHS = 1\n",
    "    LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f550a97-def9-4a1b-b1e5-709b69ce464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = (df_train.label.value_counts() / len(df_train)).to_dict()\n",
    "class_weights = dict((label_encoder[key], value) for (key, value) in class_weights.items())\n",
    "class_weights\n",
    "class_weights[2] = 0.6  # تغيير قيمة الفئة 2 إلى 0.6\n",
    "class_weights[0] = 0.2  # تغيير قيمة الفئة 0 إلى 0.2\n",
    "class_weights[1] = 0.1  # تغيير قيمة الفئة 1 إلى 0.1\n",
    "class_weights[3] = 0.1  # تغيير قيمة الفئة 3 إلى 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b178b1c6-1624-422a-ad96-e2c5ab6616ac",
   "metadata": {},
   "source": [
    "#  الدقة (Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ac9c19-55b3-4779-8f0a-3ec94f028781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_data_dir = r'C:/Users/ibrahim IA/Desktop/XRay_1/test'     \n",
    "\n",
    "# تحديد حجم الصور والدفعة\n",
    "img_width, img_height = 150, 150\n",
    "batch_size = 32\n",
    "\n",
    "# إعداد مولِّد البيانات لمجموعة الاختبار\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)  \n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical', \n",
    "    shuffle=False  \n",
    ")\n",
    "\n",
    "# التنبؤ بالتسميات باستخدام النموذج\n",
    "predictions = model.predict(test_generator)\n",
    "\n",
    "# الحصول على تسميات الفئات الحقيقية\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# تقييم الأداء، يمكنك استخدام مكتبة scikit-learn لحساب دقة النموذج\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(true_labels, np.argmax(predictions, axis=-1))\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02fe4ee-2328-4a65-91d3-d2c76f1ced0d",
   "metadata": {},
   "source": [
    "# مصفوفة الارتباط (Confusion Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9bdbf3-0115-4ffb-9c2f-7049b7cedd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# استيراد المكتبة\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# حساب مصفوفة الارتباط\n",
    "conf_matrix = confusion_matrix(true_labels, predictions.argmax(axis=-1))\n",
    "\n",
    "# عرض مصفوفة الارتباط باستخدام heatmap\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5487041b-73e5-423a-9ddb-0519a12feda7",
   "metadata": {},
   "source": [
    "#  معدلات الاستدعاء والدقة (Recall and Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a21791-e270-4b11-9e80-c95511b8ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# حساب معدل الاستدعاء والدقة\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "# حساب معدل الاستدعاء والدقة\n",
    "recall = recall_score(true_labels, predictions.argmax(axis=-1), average='weighted')\n",
    "precision = precision_score(true_labels, predictions.argmax(axis=-1), average='weighted')\n",
    "\n",
    "print(f'Recall: {recall}')\n",
    "print(f'Precision: {precision}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a53b4c9-1e01-4c4e-8faa-d4c5ded1e4b6",
   "metadata": {},
   "source": [
    "#  مقياس F1 (F1 Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6ab055-2af0-434a-8887-53661779111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# حساب مقياس F1\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# حساب مقياس F1\n",
    "f1 = f1_score(true_labels, predictions.argmax(axis=-1), average='weighted')\n",
    "print(f'F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3748f57-6090-429f-8377-79850f6ad015",
   "metadata": {},
   "source": [
    "# عرض الدقة والخسارة من تاريخ التدريب"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e2bf3a-db6e-41ed-969a-c1eb645980e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# دقة التدريب والتحقق\n",
    "plt.plot(history.history['accuracy'], label='Accuracy (Training)')\n",
    "plt.plot(history.history['val_accuracy'], label='Accuracy (Validation)')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# خسارة التدريب والتحقق\n",
    "plt.plot(history.history['loss'], label='Loss (Training)')\n",
    "plt.plot(history.history['val_loss'], label='Loss (Validation)')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116f5bb1-3c79-4653-9e01-bff7953a8133",
   "metadata": {},
   "source": [
    "# كيفية تقييم أداء النموذج باستخدام بيانات الاختبار"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8bac28-6594-4bec-9147-a54a21808b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_generator = data_generator(df_val, batch_size=cfg.BATCH_SIZE, augment=False, epochs=1)\n",
    "val_steps = int(len(df_val)/cfg.BATCH_SIZE)\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for x,y in tqdm(val_data_generator, total=val_steps):\n",
    "    pred = model.predict(x)\n",
    "    pred = np.argmax(pred, axis=-1)\n",
    "    for i in pred:\n",
    "        y_pred.append(label_decoder[i])\n",
    "    for i in y:\n",
    "        y_true.append(label_decoder[i])\n",
    "clear_output()\n",
    "print(classification_report(y_true, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dc4565-7a20-4e5c-b57b-5e2a254d50de",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_generator = data_generator(df_val, batch_size=cfg.BATCH_SIZE, augment=False, epochs=1)\n",
    "val_steps = int(len(df_val) / cfg.BATCH_SIZE)\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for x, y in tqdm(val_data_generator, total=val_steps):\n",
    "    pred = model.predict(x)\n",
    "    pred = np.argmax(pred, axis=-1)\n",
    "    \n",
    "    # Print true and predicted labels for inspection\n",
    "    print(\"True labels:\", [label_decoder[i] for i in y])\n",
    "    print(\"Predicted labels:\", [label_decoder[i] for i in pred])\n",
    "    \n",
    "    y_pred.extend(pred)\n",
    "    y_true.extend(y)\n",
    "\n",
    "clear_output()\n",
    "print(classification_report(y_true, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf222e-f09a-485c-a452-ce4e47c5232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image, model):\n",
    "    '''\n",
    "    Input the image and model, this function outputs the prediction as:\n",
    "        1. The class with the highest probability\n",
    "        2. A dictionary containing each class with their corresponding probability\n",
    "    '''\n",
    "    labels = ['NORMAL', 'TURBERCULOSIS', 'PNEUMONIA', 'COVID19']\n",
    "    image = np.array(image)\n",
    "    image = image/image.max()\n",
    "    image = image.reshape(-1,cfg.IMAGE_SIZE,cfg.IMAGE_SIZE,3)\n",
    "    probabilities = model.predict(image).reshape(-1)\n",
    "    pred = labels[np.argmax(probabilities)]\n",
    "    return pred, {x:y for x,y in zip(labels, probabilities)}\n",
    "\n",
    "INDICES = random.sample(list(df.index), 7)\n",
    "\n",
    "for INDEX in INDICES:\n",
    "\n",
    "    image = load_img(df.path[INDEX], target_size=(cfg.IMAGE_SIZE, cfg.IMAGE_SIZE))\n",
    "    pred, probabilities = predict(image, model)\n",
    "\n",
    "    x = list(probabilities.keys())\n",
    "    y = list(probabilities.values())\n",
    "\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    fig, ax = plt.subplots(1,2, figsize=(16,4), gridspec_kw={'width_ratios': [3, 4]})\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    bars = ax[1].barh(x, y, height=0.3, color=['#69c0cd', '#69c0cd', '#69c0cd', '#69c0cd'])\n",
    "    ax[1].bar_label(bars)\n",
    "    \n",
    "    ax[1].set_title('Predicted Class Probabilities')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.show()\n",
    "\n",
    "    print('Actual   :',df.label[INDEX])\n",
    "    print('Predicted:', pred)\n",
    "    print('-'*80)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac9510d-eac5-434c-89e9-eddfb67301b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_generator = data_generator(df_val, batch_size=cfg.BATCH_SIZE, augment=False, epochs=1)\n",
    "val_steps = int(len(df_val)/cfg.BATCH_SIZE)\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for x,y in tqdm(val_data_generator, total=val_steps):\n",
    "    pred = model.predict(x)\n",
    "    pred = np.argmax(pred, axis=-1)\n",
    "    for i in pred:\n",
    "        y_pred.append(label_decoder[i])\n",
    "    for i in y:\n",
    "        y_true.append(label_decoder[i])\n",
    "clear_output()\n",
    "print(classification_report(y_true, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4644d2f0-9be8-47b3-8e2c-8436746ab577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
